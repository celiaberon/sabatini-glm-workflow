{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, we will be performing a grid search to look for the best hyperparameters for our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will set up our project much like in the previous notebook, but we will will cycle through different regression models and hyperparameters to find the best model for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os \n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import glob\n",
    "\n",
    "from sglm import utils, glm_fit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet, Ridge, LinearRegression\n",
    "import torch\n",
    "import torch_linear_regression as tlr\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")  ## For Macs with Mn chips\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's create a new project. The project directory will create a data and results folder and a config file.\n",
    "\n",
    "#### You will need to edit the config file with the particular glm params you wish to use. Fields that are necessary to edit are: predictors, predictors_shift_bounds, response, and the glm_keyword_args.\n",
    "\n",
    "#### You will also need to move your data into the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\janet\\\\Documents\\\\orphan_code\\\\test_glm\\\\config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = 'test_glm'\n",
    "project_dir = r'C:\\Users\\janet\\Documents\\orphan_code'\n",
    "\n",
    "utils.create_new_project(project_name, project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.path.join(project_dir, project_name)\n",
    "files = os.listdir(project_path)\n",
    "\n",
    "assert 'data' in files, 'data folder not found! {}'.format(files)\n",
    "assert 'results' in files, 'results folder not found! {}'.format(files)\n",
    "assert 'config.yaml' in files, 'config.yaml not found! {}'.format(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(project_path, 'config.yaml')\n",
    "config = utils.load_config(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data should conform to the following convention and be saved as a *.csv:\n",
    "\n",
    "Indices / Unique Row Identifiers:\n",
    "* SessionName -- Any order is acceptable\n",
    "* TrialNumber-- Must be in chronological order, but does not need to start from zero\n",
    "* Timestamp -- Must be in chronological order, but does not need to start from zero\n",
    "\n",
    "Columns (Predictors + Responses):\n",
    "* Predictors - binary\n",
    "* Reponses - e.g. neural responses (analog or binary)\n",
    "\n",
    "Example, shown below is dummy data depicting a trial_0 that last four response timestamps:\n",
    "| SessionName | TrialNumber | Timestamp | predictor_1 | predictor_2 | predictor_3 | response_1 | response_2 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| session_0 | trial_0 | -1 | 0 | 0 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_0 | 0 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_0 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_0 | 2 | 0 | 1 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_1 | -2 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | -1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_1 | 0 | 1 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 5 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 6 | 1 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 7 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 8 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_1 | 9 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_1 | 10 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If needed, use the following function to combine multiple sessions into one csv. You will need a filename you wish to call your output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file already exists! Please remove or rename the existing file: C:\\Users\\janet\\Documents\\orphan_code\\test_glm\\data\\combined.csv, defaulting to previous version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\janet\\\\Documents\\\\orphan_code\\\\test_glm\\\\data\\\\combined.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_csv = 'combined.csv'\n",
    "\n",
    "utils.combine_csvs(project_path, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll load the data and set the columns you wish to use as fixed indices. Following this step, you can explore and add features/predictors to the dataframe as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataframe has 262972 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "input_file = os.path.join(project_path, 'data', output_csv)\n",
    "index_col = ['SessionName', 'TrialNumber', 'Timestamp']\n",
    "\n",
    "df = utils.read_data(input_file, index_col)\n",
    "\n",
    "print('Your dataframe has {} rows and {} columns'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift responses and predictors. If you do not want to shift your predictors by an amount you set, feel free to comment out the entire \"predictors_shift_bounds\" in config.yaml. We will then use the default set when we created the config file. \n",
    "\n",
    "#### For, larger datasets, you may want to sparse your training data. You can do this by seeting the sparsify argument to True in the shift_predcitors function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of rows in shifted data does not match number of rows in input data, check data if this is unexpected.\n",
      "Original length: 262972, Mask length: 262672\n",
      "Your dataframe was shifted using: [('go', [-50, 100]), ('nogo', [-50, 100]), ('reward', [-50, 100]), ('lick', [-50, 100])]\n"
     ]
    }
   ],
   "source": [
    "response_shift, df_predictors_shift, shifted_params = glm_fit.shift_predictors(config, df, sparsify=False)\n",
    "print('Your dataframe was shifted using: {}'.format(shifted_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 210137 rows and 604 columns\n",
      "Testing data has 52535 rows and 604 columns\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = glm_fit.split_data(df_predictors_shift, response_shift, config)\n",
    "\n",
    "print('Training data has {} rows and {} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Testing data has {} rows and {} columns'.format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we will perform a grid search to find the best hyperparameters for our model. We will cycle through different regression models and hyperparameters to find the best model for our data. We will only loop through `Ridge()` and `OLS()` models given that these are implemented for GPU acceleration. *Note: PyTorch is also CPU compatible, so this notebook can be run on a CPU as well*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, change to torch tensor\n",
    "X_train_tensor = utils.df_to_tensor(X_train)\n",
    "y_train_tensor = utils.df_to_tensor(y_train)\n",
    "X_test_tensor = utils.df_to_tensor(X_test)\n",
    "y_test_tensor = utils.df_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the rank\n",
    "The regression models use the closed form solutions for max performance, and if the input matrix is not full rank, the algorithm may fail. So, it is important to confirm that the input matrix is full rank before applying the regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tensor is full rank: True\n"
     ]
    }
   ],
   "source": [
    "#Check the rank\n",
    "print(f\"Training tensor is full rank: {tlr.check_full_rank(X_train_tensor).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin with OLS - no tuning required\n",
    "ols = tlr.OLS()\n",
    "ols.fit(X_train_tensor, y_train_tensor)\n",
    "ols_train_preds = ols.predict(X_train_tensor)\n",
    "ols_test_preds = ols.predict(X_test_tensor)\n",
    "\n",
    "ols_train_score = ols.score(X_test_tensor, y_test_tensor)\n",
    "print('OLS Train Score: {}'.format(ols_train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression - tune alpha using backpropogation\n",
    "\n",
    "scores_sweep = {}\n",
    "for alpha in np.geomspace(1e-5, 1e10, num=300): #loops through 300 alphas\n",
    "    model_ridge_sweep = tlr.Ridge(alpha=alpha)\n",
    "    model_ridge_sweep.fit(X_train_tensor, y_train_tensor)\n",
    "    score = model_ridge_sweep.score(X_test_tensor, y_test_tensor)\n",
    "    scores_sweep[alpha] = score\n",
    "\n",
    "## Use backpropagation to fit the alpha parameter\n",
    "fn_loss = torch.nn.MSELoss()\n",
    "alpha_optimized = torch.nn.Parameter(torch.tensor(1.0))\n",
    "optimizer = torch.optim.AdamW(params=[alpha_optimized], lr=0.3)\n",
    "losses = []\n",
    "for i in range(50):\n",
    "    model_ridge_optimized = tlr.Ridge(alpha=alpha_optimized)\n",
    "    model_ridge_optimized.fit(X_train_tensor, y_train_tensor)\n",
    "    Y_pred = model_ridge_optimized.predict(X_test_tensor)\n",
    "    loss = fn_loss(Y_pred, y_test_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "score_optimized = model_ridge_optimized.score(X_test_tensor, y_test_tensor).item()\n",
    "print(f\"Optimized Ridge Score: {score_optimized}, with alpha: {alpha_optimized.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(scores_sweep.keys()), list(scores_sweep.values()), marker='o')\n",
    "plt.plot(alpha_optimized.item(), score_optimized, marker='o')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model and parameters between Ridge and OLS\n",
    "if score_optimized > ols_train_score:\n",
    "    best_model = model_ridge_optimized\n",
    "    best_alpha = alpha_optimized.item()\n",
    "    best_score = score_optimized\n",
    "else:\n",
    "    best_model = ols\n",
    "    best_alpha = None\n",
    "    best_score = ols_train_score\n",
    "\n",
    "print(f\"Best Model: {best_model}, Best Alpha: {best_alpha}, Best Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model and parameters\n",
    "grid_sweep = {'model': best_model, 'best_score': best_score, 'alpha_optimized': alpha_optimized, 'losses': losses}\n",
    "\n",
    "import pickle\n",
    "model_path = config['Project']['project_path'] + '/models'\n",
    "model_name = 'grid_search' + '_model.pkl'\n",
    "model_full_path = os.path.join(model_path, model_name)\n",
    "with open(model_full_path, 'wb') as f:\n",
    "    pickle.dump(grid_sweep, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for opening a saved model\n",
    "model_dict_path = r'C:\\Users\\janet\\Dropbox (HMS)\\processed_photometry\\9010\\9010_base\\9010_base\\models\\grid_search_model.pkl'\n",
    "import pickle\n",
    "with open(model_dict_path, 'rb') as f:\n",
    "    grid_reg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the best paramaters to config file\n",
    "regression_type = best_model\n",
    "alpha = alpha_optimized.item()\n",
    "\n",
    "config['glm_params']['regression_type'] = regression_type\n",
    "if regression_type == 'Ridge':\n",
    "    config['glm_params']['glm_keyword_args']['ridge']['alpha'] = alpha\n",
    "\n",
    "# save back to config file\n",
    "cfg_file = os.path.join(project_dir, project_path, \"config.yaml\")\n",
    "utils.save_to_yaml(config, cfg_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can run the recommended regression with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_pred, score, beta, intercept = glm_fit.fit_glm(config, X_train, X_test, y_train, y_test, pytorch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create your model dictonary, this should include all the information you wish to save\n",
    "model_dict = {'model': model,\n",
    "                'model_type': config['glm_params']['regression_type'],\n",
    "                'y_pred': y_pred,\n",
    "                'score': score,\n",
    "                'beta': beta,\n",
    "                'intercept': intercept,\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "              }\n",
    "\n",
    "#Save your model dictionary\n",
    "glm_fit.save_model(model_dict, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save figures and results.\n",
    "The following requires non-sparse data. If you have sparse data, you will need to re-run `shift_predictors` with the `sparse` argument set to `False`.\n",
    "\n",
    "`plot_and_save` will save scatter plots of the predicted vs actual responses and the residuals and your beta coefficients. \n",
    "\n",
    "`plot_betas` will only *plot* the beta coefficients. \n",
    "\n",
    "`plot_aligned_dataStream` will plot the aligned data stream (e.g. aligned input data). You will need to run the `align_dataStream` function before running this plot.\n",
    "\n",
    "`plot_actual_v_reconstructed` will plot the actual vs reconstructed responses. You will need to run the `align_reconstructed_dataStream` function before running this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_shift, df_predictors_shift, shifted_params = glm_fit.shift_predictors(config, df, sparsify=False)\n",
    "print('Your dataframe was shifted using: {}'.format(shifted_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(project_path, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_fit.plot_and_save(config, y_pred, y_test, beta, df_predictors_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_betas(config, beta, df_predictors_shift, shifted_params, save=None, save_path=None, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align the data and plot the actual and reconstructed responses (e.g. predicted y) against the true responses (e.g. neural responses) for each prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align your actual data\n",
    "aligned_dataStream = utils.align_dataStream(config, df, shifted_params)\n",
    "\n",
    "# Plot aligned data\n",
    "utils.plot_aligned_dataStream(aligned_dataStream, config, save=True, save_path=save_path, reconstructed=False, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct your signal from your X-inputs\n",
    "recon_dataStream = utils.align_reconstructed_dataStream(config, \n",
    "                                                        df, df_predictors_shift,\n",
    "                                                         shifted_params, model)\n",
    "\n",
    "# Plot reconstructed data\n",
    "utils.plot_aligned_dataStream(recon_dataStream, config, save=True, save_path=save_path, reconstructed=True, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs reconstructed\n",
    "utils.plot_actual_v_reconstructed(config, aligned_dataStream, recon_dataStream, save=True, save_path=save_path, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For additional validation such as Leave-One-Out Cross-Validation and assessing train/test performance, please refer to the fitGLM notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sabatini-glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
